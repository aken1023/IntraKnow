# 系統架構文檔

本文檔描述了 LlamaIndex + FAISS + DeepSeek LLM 企業知識庫系統的架構設計和技術實現細節。

## 整體架構

系統採用前後端分離架構，主要由以下組件組成：

```
┌───────────────┐     ┌───────────────┐     ┌───────────────┐
│               │     │               │     │               │
│  Next.js      │     │  FastAPI      │     │  DeepSeek     │
│  前端         │────▶│  後端服務     │────▶│  LLM API      │
│               │     │               │     │               │
└───────────────┘     └───────┬───────┘     └───────────────┘
                             │
                      ┌──────▼──────┐     ┌───────────────┐
                      │             │     │               │
                      │  FAISS      │     │  文檔存儲     │
                      │  向量數據庫 │     │               │
                      │             │     │               │
                      └─────────────┘     └───────────────┘
```

## 核心組件

### 1. 前端 (Next.js)

前端使用 Next.js 框架和 Shadcn UI 組件庫構建，提供直觀的用戶界面。

**主要文件**：
- `app/page.tsx`：主頁面組件，包含查詢、上傳和系統狀態等功能
- `components/ui/`：通用 UI 組件，如按鈕、卡片等

**技術特點**：
- 使用 React 函數組件和 Hooks 進行狀態管理
- 使用 fetch API 與後端通信
- 響應式設計適配不同設備
- 即時加載動畫提升用戶體驗

### 2. 後端服務 (FastAPI)

後端服務使用 FastAPI 框架，提供 RESTful API 接口。

**主要文件**：
- `scripts/api_server.py`：API 服務器入口
- `scripts/setup_knowledge_base.py`：知識庫核心功能實現

**API 端點**：
- `POST /query`：查詢知識庫
- `POST /upload`：上傳文檔
- `GET /status`：獲取系統狀態
- `GET /documents`：列出所有文檔

### 3. 知識庫核心

知識庫核心使用 LlamaIndex 和 FAISS 實現高效的文檔索引和檢索。

**主要組件**：
- **文檔處理**：解析和分塊不同格式的文檔
- **向量化**：使用 BGE 嵌入模型生成文本向量
- **向量存儲**：使用 FAISS 高效儲存和檢索向量
- **查詢處理**：結合檢索結果和 LLM 生成回答

**處理流程**：
1. 文檔上傳 → 解析文本 → 生成嵌入向量 → 存儲到 FAISS 索引
2. 用戶查詢 → 生成查詢向量 → FAISS 檢索相似文檔 → LLM 合成回答

### 4. LLM 集成

系統使用 DeepSeek API 進行問答生成。

**集成方式**：
- 使用 REST API 調用 DeepSeek LLM 服務
- 設計有效的提示詞模板，結合檢索到的文檔和用戶查詢
- 錯誤處理和重試機制確保穩定性

## 數據流程

1. **文檔索引流程**：
   ```
   文檔上傳 → 文本提取 → 文本分塊 → 生成嵌入向量 → 存儲到 FAISS
   ```

2. **查詢處理流程**：
   ```
   用戶查詢 → 查詢向量化 → FAISS 檢索相似片段 → 提示詞構建 → LLM 生成回答 → 結果返回
   ```

## 部署架構

系統支持兩種部署方式：

### Docker 部署

使用 Docker Compose 進行容器化部署：
- `knowledge-base` 容器：運行 FastAPI 後端服務
- `nginx` 容器：作為前端服務或 API 代理

### 直接部署

- 後端：使用 `uvicorn` 或 `gunicorn` 運行 FastAPI 服務
- 前端：使用 `npm` 或 `pnpm` 構建和運行 Next.js 應用

## 技術選型考量

1. **FAISS 向量數據庫**：
   - 優點：高效的相似性搜索，支持大規模向量集
   - 考量：對於小型數據集，可以考慮 Chroma 或 Qdrant 作為替代

2. **BGE 嵌入模型**：
   - 優點：專為中文優化的開源嵌入模型
   - 考量：可以根據實際數據調整模型選擇，如 OpenAI 的 ada 模型

3. **DeepSeek LLM**：
   - 優點：強大的生成能力，優秀的中文理解能力
   - 考量：API 成本，可根據預算考慮替代模型或本地部署選項

4. **Next.js 前端**：
   - 優點：現代化框架，支持 SSR 和客戶端渲染
   - 考量：對於更簡單的場景可以考慮純 React 或其他輕量級框架

## 擴展與優化方向

1. **性能優化**：
   - 實現向量索引的增量更新
   - 添加結果緩存減少重複計算
   - 優化文檔分塊策略提升檢索質量

2. **功能擴展**：
   - 添加用戶認證和權限管理
   - 實現高級過濾和搜索功能
   - 支持更多文檔格式

3. **部署優化**：
   - 添加監控和日誌收集
   - 自動擴展配置
   - 容錯和備份策略 